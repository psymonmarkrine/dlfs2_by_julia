# 3章 word2vec

## 3.1 推論ベースの手法とニューラルネットワーク
### 3.1.1 カウントベースの手法の問題点
### 3.1.2 推論ベースの手法の概要
### 3.1.3 ニューラルネットワークにおける単語の処理方法

～  

```julia
c = [1 0 0 0 0 0 0]
W = randn(7, 3)
h = c * W
println(h)
# [0.7762100406541127 -0.04444834933302676 -0.03835470527346903]
```

～  

```julia
include("../common/layers.jl") # MatMul

c = [1 0 0 0 0 0 0]
W = randn(7, 3)
layer = MatMul(W)
h = forward(layer, c)
println(h)
# [1.5928744352708335 0.300612256900718 1.4042507868919796]
```

～  

```julia
include("../common/layers.jl") # MatMul


# サンプルのコンテキストデータ
c0 = [1 0 0 0 0 0 0]
c1 = [0 0 1 0 0 0 0]

# 重みの初期化
W_in = randn(7, 3)
W_out = randn(3, 7)

# レイヤの生成
in_layer0 = MatMul(W_in)
in_layer1 = MatMul(W_in)
out_layer = MatMul(W_out)

# 順伝搬
h0 = forward(in_layer0, c0)
h1 = forward(in_layer1, c1)
h = 0.5 * (h0 + h1)
s = forward(out_layer, h)
println(s)
# [1.766848633729323 2.524990511096121 0.20693052476884358 -0.061341396755521936 -1.0306668199248308 0.13008490778960297 -0.11827894343931313]
```

## 3.2 シンプルなword2vec
### 3.2.1 CBOWモデルの推論処理
### 3.2.2 CBOWモデルの学習
### 3.2.3 word2vecの重みと分散表現
## 3.3 学習データの準備
### 3.3.1 コンテキストとターゲット

～  

```julia
include("../common/util.jl") # preprocess

text = "You say goodbye and I say hello."
corpus, word_to_id, id_to_word = preprocess(text)
println(corpus)
# [1, 2, 3, 4, 5, 2, 6, 7]

println(id_to_word)
# Dict{Integer, AbstractString}(5 => "i", 4 => "and", 6 => "hello", 7 => ".", 2 => "say", 3 => "goodbye", 1 => "you")
```

～  

```julia
function create_contexts_target(corpus; window_size=1)
    """コンテキストとターゲットの作成
    :param corpus: コーパス（単語IDのリスト）
    :param window_size: ウィンドウサイズ（ウィンドウサイズが1のときは、単語の左右1単語がコンテキスト）
    :return:
    """
    target = corpus[(window_size+1):(end-window_size)]
    contexts = zeros(eltype(corpus), (0, 2window_size))

    for idx = (window_size+1):(length(corpus)-window_size)
        cs = zeros(eltype(corpus), (1, 0))
        for t = -window_size:window_size
            if t == 0
                continue
            end
            cs = hcat(cs, corpus[idx + t])
        end
        contexts = vcat(contexts, cs)
    end
    return contexts, target
end
```

～  

```julia
contexts, target = create_contexts_target(corpus, 1)

display(contexts)
# 6×2 Matrix{Int64}:
#  1  3
#  2  4
#  3  5
#  4  2
#  5  6
#  2  7

println(target)
# [2, 3, 4, 5, 2, 6]
```

### 3.3.2 one-hot表現への変換

～  

```julia
include("../common/util.jl") # preprocess, create_contexts_target, convert_one_hot

text = "You say goodbye and I say hello."
corpus, word_to_id, id_to_word = preprocess(text)

contexts, target = create_contexts_target(corpus, window_size=1)

vocab_size = length(word_to_id)
target = convert_one_hot(target, vocab_size)
contexts = convert_one_hot(contexts, vocab_size)
```

～  

## 3.4 CBOWモデルの実装
### 3.4.1 学習コードの実装
## 3.5 word2vecに関する補足
### 3.5.1 CBOWモデルと確率
### 3.5.2 skip-gramモデル
### 3.5.3 カウントベース v.s. 推論ベース
## 3.6 まとめ