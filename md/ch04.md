# 4章word2vecの高速化

## 4.1 word2vecの改良①
### 4.1.1 Embeddingレイヤ
### 4.1.2 Embeddingレイヤの実装

～  

```julia
julia> W = reshape(collect(0:20), 7,3)
7×3 Matrix{Int64}:
 0   7  14
 1   8  15
 2   9  16
 3  10  17
 4  11  18
 5  12  19
 6  13  20

julia> selectdim(W, 1, 3)
3-element Vector{Int64}:
  2
  9
 16

julia> selectdim(W, 1, 6)
3-element Vector{Int64}:
  5
 12
 19

```

～  

```julia
julia> idx = [2, 1, 4, 1];

julia> selectdim(W, 1, idx)
4×3 Matrix{Int64}:
 1   8  15
 0   7  14
 3  10  17
 0   7  14
```

～  

```julia
mutable struct Embedding
    params
    grads
    idx
end

Embedding(W) = Embedding([W], [zero(W)], nothing)

function forward(self::Embedding, idx)
    W = self.params[1]
    self.idx = idx
    out = selectdim(W, 1, idx)
    return out
end
```

～  

```julia
function backward(self::Embedding, dout)
    dW = self.grads[1]
    dW .= 0.0
    
    selectdim(dW, 1, self.idx) .= dout # 実は悪い例
    return nothing
end
```

～  

```julia
function backward(self::Embedding, dout)
    dW = self.grads[1]
    dW .= 0.0
    
    selectdim(dW, 1, self.idx) .+= dout
    return nothing
end
```

～  

## 4.2 word2vecの改良②
### 4.2.1 中間層以降の計算の問題点
### 4.2.2 多値分類から二値分類へ
### 4.2.3 シグモイド関数と交差エントロピー誤差
### 4.2.4 多値分類から二値分類へ（実装編）

～  

```julia
mutable struct EmbeddingDot
    embed
    params
    grads
    cache
end
function EmbeddingDot(W)
    embed = Embedding(W)
    params = embed.params
    grads = embed.grads
    return EmbeddingDot(embed, params, grads, nothing)
end

function forward(self::EmbeddingDot, h, idx)
    target_W = forward(self.embed, idx)
    out = sum(target_W * h, dims=2)

    self.cache = (h, target_W)
    return out
end

function backward(self::EmbeddingDot, dout)
    h, target_W = self.cache
    dout = reshape(dout, size(dout, 1), 1)

    dtarget_W = dout * h
    backward(self.embed, dtarget_W)
    dh = dout .* target_W
    return dh
end
```

～  

### 4.2.5 Negative Sampling
### 4.2.6 Negative Samplingのサンプリング手法

～  

```julia
julia> import Random: shuffle

# 0から9の数字の中からひとつの数字をランダムにサンプリング
julia> rand(0:9)
2

julia> rand(0:9)
8

# wordsからひとつだけランダムにサンプリング
julia> words = ["you", "say", "goodbye", "I", "hello", "."];

julia> rand(words)
"you"

# 5つだけランダムサンプリング（重複あり）
julia> rand(words, 5)
5-element Vector{String}:
 "I"
 "hello"
 "I"
 "hello"
 "you"

# 5つだけランダムサンプリング（重複なし）
julia> shuffle(words)[1:5]
5-element Vector{String}:
 "hello"
 "you"
 "say"
 "I"
 "goodbye"

julia> function choice(array; p)
           array = collect(array)
           l = min(length(array), length(p))
           r = rand()
           p = [sum(p[1:i]) for i=1:l]/sum(p[1:l])
           for i=1:l
               if p[i]>=r
                   return array[i]
               end
           end
       end

# 確率分布に従ってサンプリング
julia> choice(words, p=[0.5, 0.1, 0.05, 0.2, 0.05, 0.1])
"you"
```

～  

```julia
julia> p = [0.7 0.29 0.01]
1×3 Matrix{Float64}:
 0.7  0.29  0.01

julia> new_p = p.^0.75
1×3 Matrix{Float64}:
 0.765286  0.395183  0.0316228

julia> new_p /= sum(new_p)
1×3 Matrix{Float64}:
 0.641969  0.331504  0.0265271
```

～  

```julia
corpus = [1,2,3,4,5,2,3,4]
power = 0.75
sample_size = 2

sampler = UnigramSampler(corpus, power, sample_size)
target = [2, 4, 1]
negative_sample = get_negative_sample(sampler, target)
# 3×2 Matrix{Int32}:
#  4  5
#  3  2
#  4  3
```

～  

### 4.2.7 Negative Samplingの実装


## 4.3 改良版word2vecの学習
### 4.3.1 CBOWモデルの実装
### 4.3.2 CBOWモデルの学習コード
### 4.3.3 CBOWモデルの評価


## 4.4 word2vecに関する残りのテーマ
### 4.4.1 word2vecを使ったアプリケーションの例
### 4.4.2 単語ベクトルの評価方法


## 4.5 まとめ 